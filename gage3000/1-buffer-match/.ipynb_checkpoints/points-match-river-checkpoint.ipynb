{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238cb71-0d6b-4b48-ac26-11dd16168321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#选取站点匹配的COMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85cee4f-60dd-4a2e-9aa5-47168fe9dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating buffer... please wait.\n",
      "Performing spatial join with flowlines... please wait.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53339/1187843016.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'buffer' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  poly = dfpp.buffer(buffersize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging river data...\n",
      "Index(['stationid', 'lat', 'lon', 'geometry_x', 'index_right', 'COMID',\n",
      "       'lengthkm', 'lengthdir', 'sinuosity', 'slope', 'uparea', 'order',\n",
      "       'strmDrop_t', 'slope_taud', 'NextDownID', 'maxup', 'up1', 'up2', 'up3',\n",
      "       'up4', 'geometry_y'],\n",
      "      dtype='object')\n",
      "Calculating distance to river segments... please wait.\n",
      "Index(['stationid', 'lat', 'lon', 'geometry_x', 'index_right', 'COMID',\n",
      "       'lengthkm', 'lengthdir', 'sinuosity', 'slope', 'uparea', 'order',\n",
      "       'strmDrop_t', 'slope_taud', 'NextDownID', 'maxup', 'up1', 'up2', 'up3',\n",
      "       'up4', 'geometry_y', 'distance'],\n",
      "      dtype='object')\n",
      "Finding minimum distance per station...\n",
      "Writing to GRADES_3000points_MERIT_Basin_join.csv...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def find_nearest_river(dfpp, dfll, buffersize):\n",
    "    # Ensure both dataframes use the same CRS (coordinate reference system)\n",
    "    # Example: Convert dfpp to dfll's CRS if they are different\n",
    "    if dfpp.crs != dfll.crs:\n",
    "        print('   Reprojecting the data to a common CRS... please wait.')\n",
    "        dfpp = dfpp.to_crs(dfll.crs)\n",
    "\n",
    "    # Create buffer around the points (stations)\n",
    "    print('Creating buffer... please wait.')\n",
    "    poly = dfpp.buffer(buffersize)\n",
    "    polygpd = gpd.GeoDataFrame(dfpp, geometry=poly)\n",
    "\n",
    "    # Perform spatial join with flowlines to identify intersecting river segments\n",
    "    print('Performing spatial join with flowlines... please wait.')\n",
    "    join = gpd.sjoin(polygpd, dfll, how='inner', predicate='intersects')\n",
    "\n",
    "    # Merge the river flowline data into the result\n",
    "    print('Merging river data...')\n",
    "    merge = join.merge(dfll[['COMID', 'geometry']], on='COMID', how='left')\n",
    "    print(merge.columns)\n",
    "\n",
    "    # Calculate distance to the river segment for each station\n",
    "    print('Calculating distance to river segments... please wait.')\n",
    "    merge['distance'] = merge.apply(lambda row: row['geometry_y'].distance(Point(row['lon'], row['lat'])), axis=1)\n",
    "    print(merge.columns)\n",
    "\n",
    "\n",
    "    # Find the minimum distance per station\n",
    "    print('Finding minimum distance per station...')\n",
    "    join_min_dist = merge.groupby('stationid')['distance'].min().reset_index()\n",
    "\n",
    "    # Merge the minimum distances back to the original dataframe to get the final results\n",
    "    final_merge = pd.merge(merge, join_min_dist, on=['stationid', 'distance'], how='inner')\n",
    "\n",
    "    # Select the final relevant columns\n",
    "    final = final_merge[['stationid', 'COMID', 'distance', 'lon', 'lat']]\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load station data\n",
    "    df = pd.read_csv('GAGES_LATLON.csv')\n",
    "\n",
    "    # Convert stations to GeoDataFrame (assume it's in WGS84 initially)\n",
    "    points = [Point(lon, lat) for lon, lat in zip(df['lon'], df['lat'])]\n",
    "    dfpp = gpd.GeoDataFrame(df, geometry=points, crs=\"EPSG:4326\")  # Assume stations are in WGS84\n",
    "\n",
    "    # 获取所有匹配的shp文件\n",
    "    shp_files = glob.glob('/shared1/RESEARCH_DATA/MERIT_Basins/riv_pfaf_*.shp')\n",
    "    \n",
    "    # 读取所有shp文件并合并\n",
    "    gdfs = [gpd.read_file(f) for f in shp_files]\n",
    "    dfll = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "\n",
    "    # Ensure both dataframes use the same CRS\n",
    "    buffersize = 0.05  # ~5km buffer\n",
    "    aa = find_nearest_river(dfpp, dfll, buffersize)\n",
    "\n",
    "    # Save the result to a CSV file\n",
    "    output_file = 'GAGE3000points_MERIT_Basin_join.csv'\n",
    "    print(f'Writing to {output_file}...')\n",
    "    aa.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f9855d-c5e5-4b0d-9eb3-88f6dcc7929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "裁剪前线段数量: 3087\n",
      "裁剪后线段数量: 2021\n",
      "已处理线段数: 1/2021\n",
      "已处理线段数: 101/2021\n",
      "已处理线段数: 201/2021\n",
      "已处理线段数: 301/2021\n",
      "已处理线段数: 401/2021\n",
      "已处理线段数: 501/2021\n",
      "已处理线段数: 601/2021\n",
      "已处理线段数: 701/2021\n",
      "已处理线段数: 801/2021\n",
      "已处理线段数: 901/2021\n",
      "已处理线段数: 1001/2021\n",
      "已处理线段数: 1101/2021\n",
      "已处理线段数: 1201/2021\n",
      "已处理线段数: 1301/2021\n",
      "已处理线段数: 1401/2021\n",
      "已处理线段数: 1501/2021\n",
      "已处理线段数: 1601/2021\n",
      "已处理线段数: 1701/2021\n",
      "已处理线段数: 1801/2021\n",
      "已处理线段数: 1901/2021\n",
      "已处理线段数: 2001/2021\n",
      "生成600m线段总数: 58454\n",
      "600m segments shapefile 已保存为 'GRADES_3000points_MERIT_Basin_600m_line.shp'.\n"
     ]
    }
   ],
   "source": [
    "#将河道两端2倍河宽裁掉并进行600m切割\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import substring\n",
    "\n",
    "# 读取数据\n",
    "# dfll = dfll.to_crs(epsg=5070)\n",
    "\n",
    "width_files = glob.glob('/shared1/RESEARCH_DATA/GLOW_reach_average_zimin/region_*.csv')\n",
    "\n",
    "# 读取所有CSV文件并合并\n",
    "width_list = [pd.read_csv(f) for f in width_files]\n",
    "width = pd.concat(width_list, ignore_index=True)\n",
    "meanwidth= width.groupby('COMID')['width'].mean()\n",
    "output_file = 'meanwidth_all_regions.csv'\n",
    "meanwidth.to_csv(output_file, index=False)\n",
    "\n",
    "aa_width = aa.merge(meanwidth.reset_index()[['COMID', 'width']], on='COMID', how='left')\n",
    "aa_width_gdf = gpd.GeoDataFrame(aa_width, geometry=gpd.points_from_xy(aa.lon, aa.lat), crs='EPSG:4326')#.to_crs(epsg=5070)\n",
    "\n",
    "# 提取匹配COMID的线段\n",
    "matching_lines = dfll[dfll['COMID'].isin(aa_width_gdf['COMID'])]\n",
    "matching_lines.to_file('GRADES_3000points_MERIT_Basin_line.shp')  # 导出匹配的线段到shp文件\n",
    "\n",
    "# 假设RiverWidth信息在aa表中\n",
    "width_df = aa_width[['COMID', 'width']]\n",
    "\n",
    "# 合并获取宽度信息\n",
    "matching_lines = matching_lines.merge(width_df, on='COMID').to_crs(epsg=3395)\n",
    "\n",
    "# 根据RiverWidth裁剪线段两端（保留折点信息）\n",
    "def clip_line_keep_vertices(line, width):\n",
    "    length = line.length\n",
    "    if length > 4 * width:\n",
    "        return substring(line, 2 * width, length - 2 * width)\n",
    "    else:\n",
    "        return None  # 过短线段舍弃\n",
    "\n",
    "# 创建副本避免警告\n",
    "matching_lines_cut = matching_lines.copy()\n",
    "\n",
    "# 应用裁剪函数并保留属性\n",
    "matching_lines_cut['geometry'] = matching_lines_cut.apply(\n",
    "    lambda row: clip_line_keep_vertices(row.geometry, row.width), axis=1)\n",
    "\n",
    "print(f\"裁剪前线段数量: {len(matching_lines)}\")\n",
    "matching_lines_cut = matching_lines_cut.dropna(subset=['geometry']).reset_index(drop=True)\n",
    "print(f\"裁剪后线段数量: {len(matching_lines_cut)}\")\n",
    "\n",
    "# 分割长度\n",
    "segment_length = 600  # 如果经纬度需转换为度数: 600/110000\n",
    "\n",
    "# 线段切割函数（保留属性）\n",
    "def split_line_keep_attrs(row, segment_length):\n",
    "    line = row.geometry\n",
    "    length = line.length\n",
    "    segments = []\n",
    "\n",
    "    if length <= segment_length:\n",
    "        segments.append((row.drop('geometry').to_dict(), line))\n",
    "    else:\n",
    "        distances = list(range(0, int(length), segment_length)) + [length]\n",
    "        for i in range(len(distances) - 1):\n",
    "            segment = substring(line, distances[i], distances[i + 1])\n",
    "            segments.append((row.drop('geometry').to_dict(), segment))\n",
    "\n",
    "    return segments\n",
    "\n",
    "# 执行分割（属性与几何单独保存）\n",
    "segment_attrs = []\n",
    "segment_geoms = []\n",
    "\n",
    "for idx, row in matching_lines_cut.iterrows():\n",
    "    segments = split_line_keep_attrs(row, segment_length)\n",
    "    for attr_dict, geom in segments:\n",
    "        segment_attrs.append(attr_dict)\n",
    "        segment_geoms.append(geom)\n",
    "    if idx % 100 == 0:\n",
    "        print(f\"已处理线段数: {idx+1}/{len(matching_lines_cut)}\")\n",
    "\n",
    "# 创建DataFrame和GeoSeries，组合成GeoDataFrame\n",
    "attrs_df = pd.DataFrame(segment_attrs)\n",
    "segments_gdf = gpd.GeoDataFrame(attrs_df, geometry=segment_geoms, crs=matching_lines_cut.crs)\n",
    "\n",
    "# 保存为shp文件\n",
    "output_file = 'GAGE_3000points_MERIT_Basin_600m_line.shp'\n",
    "segments_gdf.to_file(output_file)\n",
    "\n",
    "print(f\"生成600m线段总数: {len(segments_gdf)}\")\n",
    "print(f\"600m segments shapefile 已保存为 '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1e832f2-6e9f-4eda-9fd1-2c7b07dec09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprojecting the data to a common CRS... please wait.\n",
      "Creating buffer... please wait.\n",
      "Performing spatial join with flowlines... please wait.\n",
      "Merging river data...\n",
      "Calculating distance to river segments... please wait.\n",
      "Finding minimum distance per station...\n",
      "Writing to GRADES_3000points_MERIT_Basin_600m_nearest_match.shp...\n",
      "1951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53339/1432904261.py:84: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  buffered_gdf.to_file('GRADES_3000points_MERIT_Basin_buffer_polygon_4widths.shp')\n"
     ]
    }
   ],
   "source": [
    "dfll = gpd.read_file('GAGE_3000points_MERIT_Basin_600m_line.shp').reset_index().to_crs(epsg=3395)\n",
    "def find_nearest_river(dfpp, dfll, buffersize):\n",
    "    # Ensure both dataframes use the same CRS (coordinate reference system)\n",
    "    if dfpp.crs != dfll.crs:\n",
    "        print('Reprojecting the data to a common CRS... please wait.')\n",
    "        dfpp = dfpp.to_crs(dfll.crs)\n",
    "\n",
    "    # Create buffer around the points (stations)\n",
    "    print('Creating buffer... please wait.')\n",
    "    poly = dfpp.buffer(buffersize)\n",
    "    polygpd = gpd.GeoDataFrame(dfpp, geometry=poly)\n",
    "\n",
    "    # Perform spatial join with flowlines to identify intersecting river segments\n",
    "    print('Performing spatial join with flowlines... please wait.')\n",
    "    join = gpd.sjoin(polygpd, dfll, how='inner', predicate='intersects')\n",
    "\n",
    "    # Merge the river flowline data into the result\n",
    "    print('Merging river data...')\n",
    "    merge = join.merge(dfll[['index',  'geometry']], on='index', how='left')\n",
    "\n",
    "    # Calculate distance to the river segment for each station\n",
    "    print('Calculating distance to river segments... please wait.')\n",
    "    merge['distance'] = merge.apply(lambda row: row['geometry_y'].distance(Point(row['lon'], row['lat'])), axis=1)\n",
    "\n",
    "    # Find the minimum distance per station and the corresponding river segment\n",
    "    print('Finding minimum distance per station...')\n",
    "    join_min_dist = merge.loc[merge.groupby('stationid')['distance'].idxmin()]\n",
    "\n",
    "    # Select the final relevant columns\n",
    "    final = join_min_dist[['stationid', 'lat', 'lon', 'distance', 'COMID','width', 'index', 'geometry_y']]\n",
    "\n",
    "    # Rename geometry_y to geometry for clarity\n",
    "    final = final.rename(columns={'geometry_y': 'geometry'})\n",
    "\n",
    "    # Convert to GeoDataFrame and set the correct CRS\n",
    "    final_gdf = gpd.GeoDataFrame(final, geometry='geometry', crs=dfll.crs)\n",
    "\n",
    "    return final_gdf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load station data\n",
    "    df = pd.read_csv('GAGE_LATLON.csv')\n",
    "\n",
    "    # Convert stations to GeoDataFrame (assume it's in WGS84 initially)\n",
    "    points = [Point(lon, lat) for lon, lat in zip(df['lon'], df['lat'])]\n",
    "    dfpp = gpd.GeoDataFrame(df, geometry=points, crs=\"EPSG:4326\")  # Assume stations are in WGS84\n",
    "\n",
    "    # Read river segments data (assuming it's in NAD83)\n",
    "    dfll = gpd.read_file('GAGE_3000points_MERIT_Basin_600m_line.shp').reset_index()\n",
    "\n",
    "    # Ensure both dataframes use the same CRS\n",
    "    buffersize = 600  # ~5km buffer\n",
    "    GRADES_points_MERIT_600m_nearest_match = find_nearest_river(dfpp, dfll, buffersize)\n",
    "\n",
    "    # Save the result to a Shapefile\n",
    "    output_file = 'GAGE_3000points_MERIT_Basin_600m_nearest_match.shp'\n",
    "    print(f'Writing to {output_file}...')\n",
    "    print(len(GRADES_points_MERIT_600m_nearest_match))\n",
    "    GRADES_points_MERIT_600m_nearest_match.to_file(output_file)\n",
    "\n",
    "\n",
    "\n",
    "# 定义函数处理每条线段\n",
    "def straight_line_buffer(row):\n",
    "    line_geom = row.geometry\n",
    "    width = row.width * 4\n",
    "    # 提取线段两端点坐标\n",
    "    start_point = line_geom.coords[0]\n",
    "    end_point = line_geom.coords[-1]\n",
    "    # 创建直线连接两端点\n",
    "    straight_line = LineString([start_point, end_point])\n",
    "    # 创建 buffer，buffer的两端取直角（cap_style=2）\n",
    "    buffer_poly = straight_line.buffer(width, cap_style=2)\n",
    "    return buffer_poly\n",
    "\n",
    "\n",
    "# 对matching_lines_600m创建buffer的polygon\n",
    "GRADES_points_MERIT_600m_nearest_match['buffer_polygon'] = GRADES_points_MERIT_600m_nearest_match.apply(straight_line_buffer, axis=1)\n",
    "\n",
    "# 转换为 GeoDataFrame，并设置 geometry 为 buffer_polygon\n",
    "buffered_gdf = gpd.GeoDataFrame(GRADES_points_MERIT_600m_nearest_match, geometry='buffer_polygon', crs=dfll.crs)\n",
    "buffered_gdf = buffered_gdf.drop(columns='geometry')\n",
    "# 输出为shapefile（可选）\n",
    "buffered_gdf.to_file('GAGE_3000points_MERIT_Basin_buffer_polygon_4widths.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e0126a-b076-4b6d-a341-2d8e09b6b6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
