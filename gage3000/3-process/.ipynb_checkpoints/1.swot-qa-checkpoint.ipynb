{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5dc27c7-8cfc-487a-a6cd-15b430e456e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['node_id', 'reach_id', 'time', 'lat', 'lon', 'wse', 'wse_u', 'width',\n",
      "       'width_u', 'node_q_b', 'node_q', 'ice_clim_f', 'dark_frac', 'p_width',\n",
      "       'p_n_ch_max', 'p_n_ch_mod', 'xovr_cal_q', 'xtrk_dist', 'wse_r_u',\n",
      "       'p_length'],\n",
      "      dtype='object')\n",
      "          node_id     reach_id          time           lat           lon  \\\n",
      "0  22160300290761  22160300291  7.925395e+08 -1.000000e+12 -1.000000e+12   \n",
      "1  22160300290771  22160300291  7.925395e+08 -1.000000e+12 -1.000000e+12   \n",
      "\n",
      "            wse         wse_u      width   width_u  node_q_b  node_q  \\\n",
      "0 -1.000000e+12 -1.000000e+12   2.135025  0.004025  58723843       3   \n",
      "1 -1.000000e+12 -1.000000e+12  78.151521  0.228697  58722307       3   \n",
      "\n",
      "   ice_clim_f  dark_frac  p_width  p_n_ch_max  p_n_ch_mod  xovr_cal_q  \\\n",
      "0           1        1.0     63.0           1           1           2   \n",
      "1           1        1.0     84.0           1           1           2   \n",
      "\n",
      "     xtrk_dist       wse_r_u    p_length  \n",
      "0  59642.86719 -1.000000e+12  201.890141  \n",
      "1  59640.81250 -1.000000e+12  231.661762  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)      # 显示所有列\n",
    "pd.set_option('display.max_rows', None)         # 显示所有行\n",
    "pd.set_option('display.width', None)            # 不限制显示宽度\n",
    "pd.set_option('display.max_colwidth', None)     # 不限制列宽\n",
    "\n",
    "csv_path = '/shared5/RESEARCH_DATA/SWOT/processed-node/node_20250210.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.columns)\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82302f80-eedf-4e5d-a068-b23bc13d3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始数据量: 239548\n",
      "删除缺失值后: 227946\n",
      "过滤 node_q_b <= 2194304 后: 194865\n",
      "过滤 node_q_b bit 1 后: 67706\n",
      "过滤 node_q_b bit 2 后: 40080\n",
      "过滤 node_q_b bit 3 后: 34775\n",
      "过滤 node_q_b bit 11 后: 28540\n",
      "过滤 node_q_b bit 19 后: 22306\n",
      "过滤 node_q <= 1 后: 21957\n",
      "过滤 dark_frac <= 0.4 后: 20376\n",
      "过滤 ice_clim_f <= 1 后: 20176\n",
      "过滤 xovr_cal_q <= 1 后: 20176\n",
      "过滤 p_width >= 80.0 后: 15806\n",
      "过滤 wse_r_u < 0.5 后: 15803\n",
      "过滤 15 < |xtrk_dist| < 60 后: 13526\n",
      "过滤 |p_length| > 7 后: 13526\n",
      "\n",
      "最终数据量: 13526\n",
      "总体保留率: 5.65%\n",
      "\n",
      "对比结果已保存到: ./1.swot_qa_comparison.csv\n",
      "\n",
      "=== 统计摘要 ===\n",
      "总站点数: 1942\n",
      "完全被过滤的站点数: 776\n",
      "平均保留率: 5.08%\n",
      "\n",
      "保留数据最多的前10个站点:\n",
      "          stationid  count_before  count_after  retention_rate(%)\n",
      "0      GRDC_3667020           209           81              38.76\n",
      "1      GRDC_6342800           229           62              27.07\n",
      "2      GRDC_1591231           174           62              35.63\n",
      "3     USGS_01473500           334           61              18.26\n",
      "4      GRDC_1531600           185           59              31.89\n",
      "5      GRDC_6421100           225           58              25.78\n",
      "6     USGS_06785000           198           57              28.79\n",
      "7      GRDC_6342920           208           57              27.40\n",
      "8    Chile_07308002           171           57              33.33\n",
      "9   Brazil_14550000           165           56              33.94\n",
      "10  Brazil_20489100           190           56              29.47\n",
      "\n",
      "过滤后的数据已保存到: ./0.all_matched_points_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据\n",
    "df_original = pd.read_csv('./0.all_matched_points.csv')\n",
    "\n",
    "# 统计过滤前每个stationid的数据量\n",
    "before_counts = df_original.groupby('stationid').size().reset_index(name='count_before')\n",
    "\n",
    "# 开始过滤\n",
    "df = df_original.copy()\n",
    "print(f\"初始数据量: {len(df)}\")\n",
    "\n",
    "# 替换缺失值并删除\n",
    "df = df.replace(-999999999999, np.nan).dropna()\n",
    "print(f\"删除缺失值后: {len(df)}\")\n",
    "\n",
    "# 应用各种过滤条件\n",
    "df = df[df['node_q_b'] <= 2194304]\n",
    "print(f\"过滤 node_q_b <= 2194304 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q_b'] & (1 << 1) == 0]\n",
    "print(f\"过滤 node_q_b bit 1 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q_b'] & (1 << 2) == 0]\n",
    "print(f\"过滤 node_q_b bit 2 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q_b'] & (1 << 3) == 0]\n",
    "print(f\"过滤 node_q_b bit 3 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q_b'] & (1 << 11) == 0]\n",
    "print(f\"过滤 node_q_b bit 11 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q_b'] & (1 << 19) == 0]\n",
    "print(f\"过滤 node_q_b bit 19 后: {len(df)}\")\n",
    "\n",
    "df = df[df['node_q'] <= 1]\n",
    "print(f\"过滤 node_q <= 1 后: {len(df)}\")\n",
    "\n",
    "df = df[df['dark_frac'] <= 0.4]\n",
    "print(f\"过滤 dark_frac <= 0.4 后: {len(df)}\")\n",
    "\n",
    "df = df[df['ice_clim_f'] <= 1]\n",
    "print(f\"过滤 ice_clim_f <= 1 后: {len(df)}\")\n",
    "\n",
    "df = df[df['xovr_cal_q'] <= 1]\n",
    "print(f\"过滤 xovr_cal_q <= 1 后: {len(df)}\")\n",
    "\n",
    "df = df[df['p_width'] >= 80.0]\n",
    "print(f\"过滤 p_width >= 80.0 后: {len(df)}\")\n",
    "\n",
    "df = df[df['wse_r_u'] < 0.5]\n",
    "print(f\"过滤 wse_r_u < 0.5 后: {len(df)}\")\n",
    "\n",
    "df = df[(df['xtrk_dist'].abs() > 15000) & (df['xtrk_dist'].abs() < 60000)]\n",
    "print(f\"过滤 15 < |xtrk_dist| < 60 后: {len(df)}\")\n",
    "\n",
    "df = df[abs(df['p_length']) > 7]\n",
    "print(f\"过滤 |p_length| > 7 后: {len(df)}\")\n",
    "\n",
    "df = df.drop(columns=['index_right'])\n",
    "df['date'] = pd.to_datetime('2000-01-01') + pd.to_timedelta(df['time'], unit='s')\n",
    "\n",
    "print(f\"\\n最终数据量: {len(df)}\")\n",
    "print(f\"总体保留率: {len(df)/len(df_original)*100:.2f}%\")\n",
    "\n",
    "# 统计过滤后每个stationid的数据量\n",
    "after_counts = df.groupby('stationid').size().reset_index(name='count_after')\n",
    "\n",
    "# 合并前后统计结果\n",
    "comparison = before_counts.merge(after_counts, on='stationid', how='left')\n",
    "comparison['count_after'] = comparison['count_after'].fillna(0).astype(int)\n",
    "\n",
    "# 计算变化\n",
    "comparison['count_removed'] = comparison['count_before'] - comparison['count_after']\n",
    "comparison['retention_rate(%)'] = (comparison['count_after'] / comparison['count_before'] * 100).round(2)\n",
    "\n",
    "# 排序（按照保留数据量降序）\n",
    "comparison = comparison.sort_values('count_after', ascending=False)\n",
    "\n",
    "# 添加汇总行\n",
    "summary_row = pd.DataFrame({\n",
    "    'stationid': ['TOTAL'],\n",
    "    'count_before': [comparison['count_before'].sum()],\n",
    "    'count_after': [comparison['count_after'].sum()],\n",
    "    'count_removed': [comparison['count_removed'].sum()],\n",
    "    'retention_rate(%)': [(comparison['count_after'].sum() / comparison['count_before'].sum() * 100)]\n",
    "})\n",
    "comparison = pd.concat([comparison, summary_row], ignore_index=True)\n",
    "\n",
    "# 保存对比结果\n",
    "output_file = './1.swot_qa_comparison.csv'\n",
    "comparison.to_csv(output_file, index=False)\n",
    "print(f\"\\n对比结果已保存到: {output_file}\")\n",
    "\n",
    "# 显示统计摘要\n",
    "print(\"\\n=== 统计摘要 ===\")\n",
    "print(f\"总站点数: {len(comparison)-1}\")  # 减去汇总行\n",
    "print(f\"完全被过滤的站点数: {(comparison['count_after'] == 0).sum() - 1}\")  # 减去汇总行\n",
    "print(f\"平均保留率: {comparison[comparison['stationid'] != 'TOTAL']['retention_rate(%)'].mean():.2f}%\")\n",
    "print(f\"\\n保留数据最多的前10个站点:\")\n",
    "print(comparison.head(11)[['stationid', 'count_before', 'count_after', 'retention_rate(%)']])\n",
    "\n",
    "# 保存过滤后的数据\n",
    "df.to_csv('./1.swot_qa.csv', index=False)\n",
    "print(f\"\\n过滤后的数据已保存到: ./1.swot_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9aeb8-5c47-427f-b3bd-0d6419dbb198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
