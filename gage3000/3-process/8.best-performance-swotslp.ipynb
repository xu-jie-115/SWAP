{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757a9c00-fa53-4c12-b242-d0d2337d2185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 70 workers for parallel processing\n",
      "Loading common data...\n",
      "\n",
      "Total configurations to run: 1\n",
      "Configurations:\n",
      "  A=node, B=1.5, C=noqa, D=VersionD\n",
      "\n",
      "============================================================\n",
      "Running configuration: A=node, B=1.5, C=noqa, D=VersionD\n",
      "============================================================\n",
      "Step 1: Calculating width statistics using IQR method...\n",
      "Skipped 28 stations due to small IQR (< 5):\n",
      "  Station Brazil_26800000: Q1=182.72, Q3=182.72, IQR=0.00\n",
      "  Station Brazil_31700000: Q1=111.73, Q3=115.16, IQR=3.43\n",
      "  Station Brazil_64795000: Q1=142.96, Q3=146.77, IQR=3.81\n",
      "  Station Canada_05BH004: Q1=98.55, Q3=102.17, IQR=3.62\n",
      "  Station Canada_05EF001: Q1=197.20, Q3=198.18, IQR=0.98\n",
      "  Station Canada_07EE007: Q1=103.99, Q3=108.82, IQR=4.83\n",
      "  Station Canada_07FB006: Q1=60.08, Q3=60.08, IQR=0.00\n",
      "  Station Canada_10EB001: Q1=119.95, Q3=120.14, IQR=0.19\n",
      "  Station Canada_10ED001: Q1=403.82, Q3=407.28, IQR=3.46\n",
      "  Station Canada_10HA004: Q1=90.57, Q3=90.57, IQR=0.00\n",
      "  ... and 18 more stations\n",
      "Step 2: Selecting best nodes...\n",
      "Original nodes: 4041, Selected nodes: 1766\n",
      "Step 3: Applying quality control...\n",
      "Step 4: Fitting hydraulic curves...\n",
      "Step 5: Generating hypsometric curves...\n",
      "Step 6: Validating model...\n",
      "Configuration node_1.5_noqa_VersionD_swotslp completed!\n",
      "Time for (node, 1.5, noqa, VersionD): 664.01s\n",
      "\n",
      "Generating boxplot comparisons...\n",
      "\n",
      "Total time: 667.18s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress, spearmanr\n",
    "from scipy.optimize import least_squares\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import itertools\n",
    "from numba import jit, prange\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 全局配置\n",
    "# ============================================================================\n",
    "N_WORKERS = min(mp.cpu_count() - 1, 70)  # 80\n",
    "print(f\"Using {N_WORKERS} workers for parallel processing\")\n",
    "\n",
    "# ============================================================================\n",
    "# 全局变量（用于多进程共享数据）\n",
    "# ============================================================================\n",
    "_GLOBAL_NODE_DATA = {}\n",
    "_GLOBAL_WIDTH_STATS = None\n",
    "_GLOBAL_SWOT_DATA = None\n",
    "_GLOBAL_FITTER = None\n",
    "_GLOBAL_QC_DATA = None\n",
    "_GLOBAL_SMOOTH_WINDOW = 5  # 新增：滑动窗口大小全局变量\n",
    "\n",
    "# ============================================================================\n",
    "# Numba加速的核心计算函数\n",
    "# ============================================================================\n",
    "@jit(nopython=True, parallel=True, cache=True)\n",
    "def compute_inconsistency_matrix(w, h):\n",
    "    \"\"\"使用Numba加速计算不一致性矩阵\"\"\"\n",
    "    n = len(w)\n",
    "    inverse = np.zeros(n, dtype=np.int64)\n",
    "    for i in prange(n):\n",
    "        count = 0\n",
    "        for j in range(n):\n",
    "            w_diff = w[i] - w[j]\n",
    "            h_diff = h[i] - h[j]\n",
    "            if w_diff * h_diff < 0:\n",
    "                count += 1\n",
    "        inverse[i] = count\n",
    "    return inverse\n",
    "\n",
    "@jit(nopython=True, cache=True)\n",
    "def calculate_areas_numba(w_list, h_list, w50, a50):\n",
    "    \"\"\"使用Numba加速面积计算\"\"\"\n",
    "    n = len(w_list)\n",
    "    areas = np.full(n, np.nan)\n",
    "    \n",
    "    # 边界检查：如果数据点太少，直接返回\n",
    "    if n < 2:\n",
    "        return areas\n",
    "    \n",
    "    idx50 = np.searchsorted(w_list, w50)\n",
    "    if idx50 >= n:\n",
    "        idx50 = n - 1\n",
    "    if idx50 < 1:\n",
    "        idx50 = 1\n",
    "    \n",
    "    # 防止除零错误\n",
    "    denom = w_list[idx50] - w_list[idx50-1]\n",
    "    if abs(denom) < 1e-10:\n",
    "        # 如果宽度差太小，使用平均值\n",
    "        h50 = (h_list[idx50-1] + h_list[idx50]) / 2.0\n",
    "    else:\n",
    "        h50 = (h_list[idx50-1] * (w_list[idx50] - w50) +\n",
    "               h_list[idx50] * (w50 - w_list[idx50-1])) / denom\n",
    "    \n",
    "    areas[idx50] = a50 + 0.5 * (w50 + w_list[idx50]) * (h_list[idx50] - h50)\n",
    "    \n",
    "    for i in range(idx50 + 1, n):\n",
    "        areas[i] = areas[i-1] + 0.5 * (w_list[i-1] + w_list[i]) * \\\n",
    "                  (h_list[i] - h_list[i-1])\n",
    "    \n",
    "    for i in range(idx50 - 1, -1, -1):\n",
    "        areas[i] = areas[i+1] - 0.5 * (w_list[i+1] + w_list[i]) * \\\n",
    "                  (h_list[i+1] - h_list[i])\n",
    "    \n",
    "    return areas\n",
    "\n",
    "@jit(nopython=True, cache=True)\n",
    "def nse_numba(observed, simulated):\n",
    "    \"\"\"Numba加速的NSE计算\"\"\"\n",
    "    obs_mean = np.mean(observed)\n",
    "    numerator = np.sum((observed - simulated)**2)\n",
    "    denominator = np.sum((observed - obs_mean)**2)\n",
    "    if denominator == 0:\n",
    "        return np.nan\n",
    "    return 1 - numerator / denominator\n",
    "\n",
    "@jit(nopython=True, cache=True)\n",
    "def kge_numba(observed, simulated):\n",
    "    \"\"\"Numba加速的KGE计算\"\"\"\n",
    "    obs_mean = np.mean(observed)\n",
    "    sim_mean = np.mean(simulated)\n",
    "    obs_std = np.std(observed)\n",
    "    sim_std = np.std(simulated)\n",
    "    \n",
    "    if obs_std == 0 or sim_std == 0 or obs_mean == 0 or sim_mean == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    n = len(observed)\n",
    "    cov = np.sum((observed - obs_mean) * (simulated - sim_mean)) / n\n",
    "    r = cov / (obs_std * sim_std)\n",
    "    \n",
    "    alpha = sim_mean / obs_mean\n",
    "    beta = (sim_std / sim_mean) / (obs_std / obs_mean)  # 变异系数比\n",
    "    \n",
    "    return 1 - np.sqrt((r - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "# ============================================================================\n",
    "# 全局并行处理函数（必须在模块级别定义才能被pickle）\n",
    "# ============================================================================\n",
    "def _compute_node_corr(node_id):\n",
    "    \"\"\"计算单个节点的秩相关系数\"\"\"\n",
    "    global _GLOBAL_NODE_DATA\n",
    "    data = _GLOBAL_NODE_DATA.get(node_id)\n",
    "    if data is None or len(data['width']) < 5:\n",
    "        return (node_id, data['stationid'] if data else None, 0.0)\n",
    "    \n",
    "    try:\n",
    "        corr, _ = spearmanr(data['width'], data['wse'])\n",
    "        if np.isnan(corr):\n",
    "            corr = 0.0\n",
    "    except:\n",
    "        corr = 0.0\n",
    "    \n",
    "    return (node_id, data['stationid'], corr)\n",
    "\n",
    "def _process_qc_station(stationid):\n",
    "    \"\"\"处理单个站点的质控（全局函数版本）\"\"\"\n",
    "    global _GLOBAL_WIDTH_STATS, _GLOBAL_SWOT_DATA\n",
    "    \n",
    "    if _GLOBAL_WIDTH_STATS is None or stationid not in _GLOBAL_WIDTH_STATS.index:\n",
    "        return None\n",
    "    \n",
    "    df = _GLOBAL_SWOT_DATA[_GLOBAL_SWOT_DATA['stationid'] == stationid].copy()\n",
    "    if len(df) < 5:\n",
    "        return None\n",
    "    \n",
    "    # 步骤1: 不确定度筛选\n",
    "    df['width_u_r'] = df['width_u'] / df['width']\n",
    "    df1 = df[(df['wse_u'] <= 0.4) & (df['width_u_r'] <= 0.1)]\n",
    "    if len(df1) < 5:\n",
    "        return None\n",
    "    \n",
    "    # 步骤2: 顺序一致性剔除\n",
    "    df2 = _remove_inconsistent_points(df1)\n",
    "    if len(df2) < 5:\n",
    "        return None\n",
    "    \n",
    "    # 步骤3: 离群值剔除\n",
    "    w_low = _GLOBAL_WIDTH_STATS.loc[stationid, 'w_low']\n",
    "    w_high = _GLOBAL_WIDTH_STATS.loc[stationid, 'w_high']\n",
    "    d_bankfull = 0.27 * (w_high / 7.2) ** 0.6\n",
    "    h50 = df2['wse'].median()\n",
    "    \n",
    "    df3 = df2[(df2['wse'] <= h50 + d_bankfull) & (df2['wse'] >= h50 - d_bankfull)]\n",
    "    \n",
    "    return df3 if len(df3) >= 5 else None\n",
    "\n",
    "def _remove_inconsistent_points(df, inverse_ratio_thresh=0.5):\n",
    "    \"\"\"顺序一致性剔除\"\"\"\n",
    "    indices_to_keep = list(df.index)\n",
    "    \n",
    "    while True:\n",
    "        n = len(indices_to_keep)\n",
    "        if n < 5:\n",
    "            break\n",
    "        \n",
    "        df_current = df.loc[indices_to_keep]\n",
    "        w = df_current['width'].values.astype(np.float64)\n",
    "        h = df_current['wse'].values.astype(np.float64)\n",
    "        \n",
    "        inverse = compute_inconsistency_matrix(w, h)\n",
    "        \n",
    "        idx_max = np.argmax(inverse)\n",
    "        if inverse[idx_max] / n < inverse_ratio_thresh:\n",
    "            break\n",
    "        \n",
    "        indices_to_keep.pop(idx_max)\n",
    "    \n",
    "    return df.loc[indices_to_keep]\n",
    "\n",
    "def _fit_station_wrapper(stationid):\n",
    "    \"\"\"拟合单个站点（全局函数版本）\"\"\"\n",
    "    global _GLOBAL_FITTER, _GLOBAL_QC_DATA\n",
    "    \n",
    "    df_station = _GLOBAL_QC_DATA[_GLOBAL_QC_DATA['stationid'] == stationid]\n",
    "    if len(df_station) == 0:\n",
    "        return None\n",
    "    \n",
    "    comid = df_station.iloc[0]['COMID']\n",
    "    return _GLOBAL_FITTER.fit_station(df_station, stationid, comid)\n",
    "\n",
    "def _validate_station_wrapper(args):\n",
    "    \"\"\"验证单个站点（全局函数版本）\"\"\"\n",
    "    # 【修改】添加 skip_width_filter 参数\n",
    "    s, df_hypso, df_width, df_val_folder, df_fit, start_date, skip_width_filter = args\n",
    "    \n",
    "    file_path = os.path.join(df_val_folder, f'{s}.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df_val = pd.read_csv(file_path)\n",
    "        num_days = len(df_val)\n",
    "        df_val['date'] = pd.date_range(start=start_date, periods=num_days, freq='D')\n",
    "        df_val['stationid'] = s\n",
    "        df_val = df_val.dropna(subset=['qobs'])\n",
    "        \n",
    "        df_width_s = df_width[df_width['stationid'] == s]\n",
    "        df_val = df_val.merge(df_width_s, on=['stationid', 'date'], how='inner')\n",
    "        \n",
    "        df_curve = df_hypso[df_hypso['stationid'] == s].reset_index(drop=True)\n",
    "        station_fit = df_fit[df_fit['stationid'] == s]\n",
    "        if station_fit.empty or df_curve.empty:\n",
    "            return None\n",
    "        \n",
    "        row = station_fit.iloc[0]\n",
    "        w_low, w_high, slp = row['w_low'], row['w_high'], row['slp']\n",
    "        \n",
    "        # 【修改】根据 skip_width_filter 决定是否进行宽度筛选\n",
    "        if skip_width_filter:\n",
    "            # datemean模式：不对width做筛选，只去重\n",
    "            df_val = df_val.drop_duplicates('date')\n",
    "        else:\n",
    "            # node模式：正常进行宽度筛选\n",
    "            df_val = df_val[\n",
    "                (df_val['width'] >= w_low) &\n",
    "                (df_val['width'] <= w_high)\n",
    "            ].drop_duplicates('date')\n",
    "        \n",
    "        if len(df_val) < 10:\n",
    "            return None\n",
    "        \n",
    "        # 向量化插值\n",
    "        curve_width = df_curve['width'].values\n",
    "        curve_area = df_curve['area'].values\n",
    "        val_width = df_val['width'].values\n",
    "        \n",
    "        area_hypso = np.interp(val_width, curve_width, curve_area)\n",
    "        \n",
    "        df_val['area_hypso'] = area_hypso\n",
    "        df_val['Q_est'] = (area_hypso**(5/3) * val_width**(-2/3) * slp**0.5 / 0.035)\n",
    "        \n",
    "        df_val = df_val.dropna()\n",
    "        if len(df_val) < 10:\n",
    "            return None\n",
    "        \n",
    "        obs = df_val['qobs'].values.astype(np.float64)\n",
    "        sim = df_val['Q_est'].values.astype(np.float64)\n",
    "        \n",
    "        kge_val = kge_numba(obs, sim)\n",
    "        nse_val = nse_numba(obs, sim)\n",
    "        rmse = np.sqrt(np.mean((obs - sim)**2))\n",
    "        nrmse_val = rmse / np.mean(obs)\n",
    "        \n",
    "        df_val['kge'] = kge_val\n",
    "        df_val['nse'] = nse_val\n",
    "        df_val['nrmse'] = nrmse_val\n",
    "        \n",
    "        return df_val[['stationid', 'date', 'width', 'area_hypso',\n",
    "                       'qobs', 'Q_est', 'kge', 'nse', 'nrmse']]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing station {s}: {e}\")\n",
    "        return None\n",
    "\n",
    "def _rolling_median_group(group):\n",
    "    \"\"\"滑动中值处理 - 使用全局变量控制窗口大小\"\"\"\n",
    "    global _GLOBAL_SMOOTH_WINDOW\n",
    "    window = _GLOBAL_SMOOTH_WINDOW\n",
    "    group = group.sort_values('date')\n",
    "    group['width'] = group['width'].rolling(window=window, center=True, min_periods=1).median()\n",
    "    group['wse'] = group['wse'].rolling(window=window, center=True, min_periods=1).median()\n",
    "    return group\n",
    "\n",
    "# ============================================================================\n",
    "# 模块1: 数据统计工具 (修改为IQR方法)\n",
    "# ============================================================================\n",
    "class WidthStatistics:\n",
    "    \"\"\"计算河流宽度的统计特征 - 使用IQR方法\"\"\"\n",
    "    \n",
    "    # 定义IQR配置：{选项: IQR倍数}\n",
    "    # w_low = Q1 - k * IQR\n",
    "    # w_high = Q3 + k * IQR\n",
    "    IQR_CONFIG = {\n",
    "        '1.0': 1.0,\n",
    "        '1.5': 1.5,\n",
    "        '2.0': 2.0,\n",
    "        '2.5': 2.5,\n",
    "        '3.0': 3.0,\n",
    "        '4.0': 4.0\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_width_iqr(df, min_width=30, valid_ratio=0.95, min_iqr=5):\n",
    "        \"\"\"\n",
    "        计算每个站点的宽度IQR范围\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame\n",
    "            输入数据\n",
    "        min_width : float\n",
    "            最小有效宽度\n",
    "        valid_ratio : float\n",
    "            有效数据比例阈值\n",
    "        min_iqr : float\n",
    "            最小IQR阈值，当IQR小于此值时跳过该站点\n",
    "        \"\"\"\n",
    "        stationids = df['stationid'].unique()\n",
    "        result_data = []\n",
    "        skipped_stations = []\n",
    "        \n",
    "        for stationid in stationids:\n",
    "            station_data_all = df[df['stationid'] == stationid]['width'].dropna()\n",
    "            station_data = station_data_all[station_data_all >= min_width]\n",
    "            \n",
    "            if len(station_data_all) == 0:\n",
    "                continue\n",
    "            if len(station_data) / len(station_data_all) < valid_ratio:\n",
    "                continue\n",
    "            \n",
    "            if len(station_data) > 10:\n",
    "                w50 = station_data.median()\n",
    "                \n",
    "                # 计算Q1, Q3和IQR\n",
    "                q1 = station_data.quantile(0.25)\n",
    "                q3 = station_data.quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                \n",
    "                # 检查IQR是否足够大，如果Q1和Q3太接近则跳过该站点\n",
    "                if iqr < min_iqr:\n",
    "                    skipped_stations.append((stationid, q1, q3, iqr))\n",
    "                    continue\n",
    "                \n",
    "                row_data = {\n",
    "                    'stationid': stationid,\n",
    "                    'w50': w50,\n",
    "                    'Q1': q1,\n",
    "                    'Q3': q3,\n",
    "                    'IQR': iqr\n",
    "                }\n",
    "                \n",
    "                # 动态计算所有IQR倍数配置的范围\n",
    "                for key, k in WidthStatistics.IQR_CONFIG.items():\n",
    "                    w_low = max(q1 - k * iqr, min_width)  # 确保不低于最小宽度\n",
    "                    w_high = q3 + k * iqr\n",
    "                    row_data[f'w_low_iqr{key}'] = w_low\n",
    "                    row_data[f'w_high_iqr{key}'] = w_high\n",
    "                \n",
    "                result_data.append(row_data)\n",
    "        \n",
    "        # 打印跳过的站点信息\n",
    "        if skipped_stations:\n",
    "            print(f\"Skipped {len(skipped_stations)} stations due to small IQR (< {min_iqr}):\")\n",
    "            for sid, q1, q3, iqr in skipped_stations[:10]:  # 只打印前10个\n",
    "                print(f\"  Station {sid}: Q1={q1:.2f}, Q3={q3:.2f}, IQR={iqr:.2f}\")\n",
    "            if len(skipped_stations) > 10:\n",
    "                print(f\"  ... and {len(skipped_stations) - 10} more stations\")\n",
    "        \n",
    "        return pd.DataFrame(result_data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_iqr_columns(b_option):\n",
    "        \"\"\"根据B选项获取对应的IQR列名\"\"\"\n",
    "        if b_option not in WidthStatistics.IQR_CONFIG:\n",
    "            raise ValueError(f\"Invalid B option: {b_option}. Valid options: {list(WidthStatistics.IQR_CONFIG.keys())}\")\n",
    "        \n",
    "        return f'w_low_iqr{b_option}', f'w_high_iqr{b_option}'\n",
    "    \n",
    "    # 保留旧方法以兼容（如果需要）\n",
    "    @staticmethod\n",
    "    def calculate_width_percentiles(df, min_width=30, valid_ratio=0.95, min_iqr=5):\n",
    "        \"\"\"计算每个站点的宽度分位数（保留用于兼容）\"\"\"\n",
    "        return WidthStatistics.calculate_width_iqr(df, min_width, valid_ratio, min_iqr)\n",
    "\n",
    "# ============================================================================\n",
    "# 模块2: 节点选择\n",
    "# ============================================================================\n",
    "class NodeSelector:\n",
    "    \"\"\"为每个站点选择最优节点\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def select_best_nodes(df_swot, min_data_points=10):\n",
    "        \"\"\"为每个站点选择秩相关系数最大的节点\"\"\"\n",
    "        global _GLOBAL_NODE_DATA\n",
    "        \n",
    "        # 向量化计算节点数据量\n",
    "        node_counts = df_swot.groupby('node_id').size()\n",
    "        valid_nodes = node_counts[node_counts >= min_data_points].index\n",
    "        df_swot = df_swot[df_swot['node_id'].isin(valid_nodes)].copy()\n",
    "        \n",
    "        # 预计算每个节点的数据\n",
    "        _GLOBAL_NODE_DATA = {}\n",
    "        for node_id, group in df_swot.groupby('node_id'):\n",
    "            _GLOBAL_NODE_DATA[node_id] = {\n",
    "                'width': group['width'].values,\n",
    "                'wse': group['wse'].values,\n",
    "                'stationid': group['stationid'].iloc[0]\n",
    "            }\n",
    "        \n",
    "        node_ids = list(_GLOBAL_NODE_DATA.keys())\n",
    "        \n",
    "        # 使用进程池并行计算\n",
    "        with mp.Pool(processes=N_WORKERS) as pool:\n",
    "            results = pool.map(_compute_node_corr, node_ids)\n",
    "        \n",
    "        df_node = pd.DataFrame(results, columns=['node_id', 'stationid', 'rank_corr'])\n",
    "        df_node = df_node.dropna(subset=['stationid'])\n",
    "        \n",
    "        # 选择每个站点的最大秩相关系数节点\n",
    "        max_idx = df_node.groupby('stationid')['rank_corr'].idxmax()\n",
    "        df_node_rmax = df_node.loc[max_idx]\n",
    "        \n",
    "        # 筛选数据\n",
    "        df_filtered = df_swot[df_swot['node_id'].isin(df_node_rmax['node_id'])]\n",
    "        \n",
    "        print(f\"Original nodes: {len(df_node)}, Selected nodes: {len(df_node_rmax)}\")\n",
    "        \n",
    "        # 清理全局变量\n",
    "        _GLOBAL_NODE_DATA = {}\n",
    "        \n",
    "        return df_filtered, df_node_rmax\n",
    "\n",
    "# ============================================================================\n",
    "# 模块3: 数据质控\n",
    "# ============================================================================\n",
    "class DataQualityControl:\n",
    "    \"\"\"SWOT数据质量控制\"\"\"\n",
    "    \n",
    "    def __init__(self, width_stats):\n",
    "        self.width_stats = width_stats.set_index('stationid')\n",
    "    \n",
    "    def apply_qc(self, df_swot, draw_figure=False, output_folder=None):\n",
    "        \"\"\"应用完整的质量控制流程\"\"\"\n",
    "        global _GLOBAL_WIDTH_STATS, _GLOBAL_SWOT_DATA\n",
    "        \n",
    "        _GLOBAL_WIDTH_STATS = self.width_stats\n",
    "        _GLOBAL_SWOT_DATA = df_swot\n",
    "        \n",
    "        stationids = df_swot['stationid'].unique()\n",
    "        \n",
    "        # 使用进程池并行处理\n",
    "        with mp.Pool(processes=N_WORKERS) as pool:\n",
    "            results = pool.map(_process_qc_station, stationids)\n",
    "        \n",
    "        # 清理全局变量\n",
    "        _GLOBAL_WIDTH_STATS = None\n",
    "        _GLOBAL_SWOT_DATA = None\n",
    "        \n",
    "        # 合并结果\n",
    "        results = [df for df in results if df is not None]\n",
    "        \n",
    "        if not results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        result = pd.concat(results)\n",
    "        result = result.drop_duplicates(subset=['node_id', 'date', 'stationid'])\n",
    "        result.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# ============================================================================\n",
    "# 模块4: 水位-面积曲线拟合\n",
    "# ============================================================================\n",
    "class HydraulicCurveFitter:\n",
    "    \"\"\"拟合水位-宽度关系曲线\"\"\"\n",
    "    \n",
    "    def __init__(self, width_stats, river_attrs, skip_width_filter=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        width_stats : DataFrame\n",
    "            宽度统计数据\n",
    "        river_attrs : DataFrame\n",
    "            河流属性数据\n",
    "        skip_width_filter : bool\n",
    "            是否跳过宽度筛选（用于datemean模式）\n",
    "        \"\"\"\n",
    "        self.width_stats = width_stats.set_index('stationid')\n",
    "        self.river_attrs = river_attrs.set_index('COMID')\n",
    "        self.skip_width_filter = skip_width_filter\n",
    "        \n",
    "        self.R_list = np.array([0.5, 1, 2, 4, 8])\n",
    "        self.GAP_list = np.array([-0.3, -0.1, 0, 0.1, 0.3])\n",
    "        self.W_list = np.array([0.3, 0.5, 0.7])\n",
    "    \n",
    "    @staticmethod\n",
    "    def power_function(params, X, y):\n",
    "        wse0, a, b = params\n",
    "        return y - (wse0 + a * X**b)\n",
    "    \n",
    "    def loss_function(self, z, weight, n_swot):\n",
    "        rho = np.zeros((3, len(z)))\n",
    "        rho[0] = 2 * ((1 + z)**0.5 - 1)\n",
    "        rho[1] = (1 + z)**(-0.5)\n",
    "        rho[2] = -0.5 * (1 + z)**(-1.5)\n",
    "        \n",
    "        factor = (n_swot - 2) / weight * (1 - weight) / 2\n",
    "        rho[:, 0] *= factor\n",
    "        rho[:, 1] *= factor\n",
    "        \n",
    "        return rho\n",
    "    \n",
    "    def calculate_h50(self, df, w50):\n",
    "        df = df.copy()\n",
    "        df['w50_diff'] = np.abs(df['width'] - w50)\n",
    "        df = df.sort_values('w50_diff')\n",
    "        \n",
    "        xdata = df.iloc[:5]['width'].values\n",
    "        ydata = df.iloc[:5]['wse'].values\n",
    "        xdata_uni = np.unique(xdata)\n",
    "        \n",
    "        if len(xdata_uni) < 2:\n",
    "            return df.iloc[:5]['wse'].mean()\n",
    "        \n",
    "        res = linregress(xdata, ydata)\n",
    "        if res[0] >= 0:\n",
    "            return res[0] * w50 + res[1]\n",
    "        else:\n",
    "            return df.iloc[:5]['wse'].mean()\n",
    "    \n",
    "    def fit_station(self, df_station, stationid, comid):\n",
    "        \"\"\"拟合单个站点的水位-宽度关系\"\"\"\n",
    "        if stationid not in self.width_stats.index:\n",
    "            return None\n",
    "        if comid not in self.river_attrs.index:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            q50 = self.river_attrs.loc[comid, 'q50_weighted']\n",
    "            slp = self.river_attrs.loc[comid, 'slope']\n",
    "            w50, w_low, w_high = self.width_stats.loc[stationid, ['w50', 'w_low', 'w_high']]\n",
    "            d_bankfull = 0.27 * (w_high / 7.2)**0.6\n",
    "            \n",
    "            h50 = self.calculate_h50(df_station, w50)\n",
    "            a50 = (q50 * 0.035 / slp**0.5 * w50**(2/3))**(3/5)\n",
    "            \n",
    "            # 根据skip_width_filter决定是否进行宽度筛选\n",
    "            if self.skip_width_filter:\n",
    "                # datemean模式：不对width做筛选\n",
    "                df_filtered = df_station.copy()\n",
    "            else:\n",
    "                # node模式：正常进行宽度筛选\n",
    "                df_filtered = df_station[\n",
    "                    (df_station['width'] >= w_low) &\n",
    "                    (df_station['width'] <= w_high)\n",
    "                ]\n",
    "            \n",
    "            if len(df_filtered) < 3:\n",
    "                return None\n",
    "            \n",
    "            swot_wsemax = df_filtered.sort_values('wse', ascending=False).iloc[0]\n",
    "            d_wsemax = 0.27 * (swot_wsemax['width'] / 7.2)**0.6\n",
    "            \n",
    "            results = []\n",
    "            for r_low in self.R_list:\n",
    "                for gap in self.GAP_list:\n",
    "                    for weight in self.W_list:\n",
    "                        result = self._fit_single_config(\n",
    "                            df_filtered, r_low, gap, weight,\n",
    "                            w_low, w_high, w50, h50, a50,\n",
    "                            swot_wsemax, d_bankfull, d_wsemax, slp, q50\n",
    "                        )\n",
    "                        if result is not None:\n",
    "                            result.update({\n",
    "                                'stationid': stationid,\n",
    "                                'COMID': comid,\n",
    "                                'R': r_low,\n",
    "                                'GAP': gap,\n",
    "                                'W': weight\n",
    "                            })\n",
    "                            results.append(result)\n",
    "            \n",
    "            return pd.DataFrame(results) if results else None\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _fit_single_config(self, df, r_low, gap, weight, w_low, w_high, w50,\n",
    "                          h50, a50, swot_wsemax, d_bankfull, d_wsemax, slp, q50):\n",
    "        \"\"\"拟合单个参数配置\"\"\"\n",
    "        a_low = a50 * (r_low + 1) / r_low / w50**(r_low + 1)\n",
    "        h0 = h50 - a_low * w50**r_low\n",
    "        h_low = h0 + a_low * w_low**r_low\n",
    "        h_high = swot_wsemax['wse'] + (d_bankfull - d_wsemax) + gap * d_bankfull\n",
    "        \n",
    "        xdata = np.insert(df['width'].values, 0, [w_low, w_high])\n",
    "        ydata = np.insert(df['wse'].values, 0, [h_low, h_high])\n",
    "        a_default = (h_high - h0) / w_high**2\n",
    "        \n",
    "        n_swot = len(df)\n",
    "        \n",
    "        def loss_wrapper(z):\n",
    "            return self.loss_function(z, weight, n_swot)\n",
    "        \n",
    "        try:\n",
    "            ls = least_squares(\n",
    "                self.power_function,\n",
    "                x0=[h0, a_default, 2],\n",
    "                loss=loss_wrapper,\n",
    "                args=(xdata, ydata),\n",
    "                max_nfev=100\n",
    "            )\n",
    "            \n",
    "            if ls.status > 0:\n",
    "                wse0, a, b = ls.x\n",
    "                if a * b < 0:\n",
    "                    return None\n",
    "                \n",
    "                return {\n",
    "                    'wse0': wse0, 'a': a, 'b': b,\n",
    "                    'a50': a50, 'w50': w50, 'q50': q50,\n",
    "                    'w_low': w_low, 'w_high': w_high,\n",
    "                    'h_low': h_low, 'h_high': h_high,\n",
    "                    'slp': slp\n",
    "                }\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit_all_stations(self, df_qc):\n",
    "        \"\"\"并行拟合所有站点\"\"\"\n",
    "        global _GLOBAL_FITTER, _GLOBAL_QC_DATA\n",
    "        \n",
    "        _GLOBAL_FITTER = self\n",
    "        _GLOBAL_QC_DATA = df_qc\n",
    "        \n",
    "        unique_stations = df_qc['stationid'].unique()\n",
    "        \n",
    "        # 使用进程池并行处理\n",
    "        with mp.Pool(processes=N_WORKERS) as pool:\n",
    "            results = pool.map(_fit_station_wrapper, unique_stations)\n",
    "        \n",
    "        # 清理全局变量\n",
    "        _GLOBAL_FITTER = None\n",
    "        _GLOBAL_QC_DATA = None\n",
    "        \n",
    "        results = [df for df in results if df is not None]\n",
    "        \n",
    "        if results:\n",
    "            return pd.concat(results, ignore_index=True)\n",
    "        return None\n",
    "\n",
    "# ============================================================================\n",
    "# 模块5: 水位-面积曲线生成\n",
    "# ============================================================================\n",
    "class HypsometricCurveGenerator:\n",
    "    \"\"\"生成水位-面积关系曲线\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_curves(df_fit, n_points=100):\n",
    "        \"\"\"为所有站点生成中值水位-面积曲线\"\"\"\n",
    "        stationids = sorted(df_fit['stationid'].unique())\n",
    "        df_res = []\n",
    "        \n",
    "        for s in stationids:\n",
    "            df_station = df_fit[df_fit['stationid'] == s]\n",
    "            w_low, w_high, w50, a50 = df_station.iloc[0][\n",
    "                ['w_low', 'w_high', 'w50', 'a50']\n",
    "            ]\n",
    "            \n",
    "            # 边界检查：跳过无效的宽度范围\n",
    "            if w_high <= w_low or abs(w_high - w_low) < 1e-6:\n",
    "                print(f\"Warning: Skipping station {s} due to invalid width range (w_low={w_low}, w_high={w_high})\")\n",
    "                continue\n",
    "            \n",
    "            wse0 = df_station['wse0'].values\n",
    "            a = df_station['a'].values\n",
    "            b = df_station['b'].values\n",
    "            \n",
    "            w_list = np.linspace(w_low, w_high, n_points)\n",
    "            \n",
    "            # 向量化计算\n",
    "            heights_all = wse0[:, np.newaxis] + a[:, np.newaxis] * w_list**b[:, np.newaxis]\n",
    "            h_list = np.median(heights_all, axis=0)\n",
    "            hmax = np.max(heights_all, axis=0)\n",
    "            hmin = np.min(heights_all, axis=0)\n",
    "            \n",
    "            # Numba加速的面积计算\n",
    "            areas = calculate_areas_numba(w_list, h_list, w50, a50)\n",
    "            \n",
    "            df_curve = pd.DataFrame({\n",
    "                'stationid': s,\n",
    "                'width': w_list,\n",
    "                'wse': h_list,\n",
    "                'wse_max': hmax,\n",
    "                'wse_min': hmin,\n",
    "                'area': areas\n",
    "            })\n",
    "            \n",
    "            df_res.append(df_curve)\n",
    "        \n",
    "        return pd.concat(df_res, ignore_index=True) if df_res else pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# 模块6: 验证与评估\n",
    "# ============================================================================\n",
    "class ModelValidator:\n",
    "    \"\"\"模型验证与性能评估\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def relative_rmse(observed, simulated):\n",
    "        rmse = np.sqrt(mean_squared_error(observed, simulated))\n",
    "        return rmse / np.mean(observed)\n",
    "    \n",
    "    def validate(self, df_hypso, df_width, df_val_folder, df_fit, skip_width_filter=False):\n",
    "        \"\"\"\n",
    "        验证模型性能\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        skip_width_filter : bool\n",
    "            是否跳过宽度筛选（用于datemean模式）\n",
    "        \"\"\"\n",
    "        stationids = sorted(df_hypso['stationid'].unique())\n",
    "        start_date = pd.to_datetime('1979-01-01')\n",
    "        \n",
    "        # 【修改】在参数列表中添加 skip_width_filter\n",
    "        args_list = [\n",
    "            (s, df_hypso, df_width, df_val_folder, df_fit, start_date, skip_width_filter)\n",
    "            for s in stationids\n",
    "        ]\n",
    "        \n",
    "        # 使用进程池并行处理\n",
    "        with mp.Pool(processes=N_WORKERS) as pool:\n",
    "            results = pool.map(_validate_station_wrapper, args_list)\n",
    "        \n",
    "        results = [df for df in results if df is not None]\n",
    "        \n",
    "        return pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# 配置运行函数\n",
    "# ============================================================================\n",
    "def run_configuration(a, b, c, d, e, common_data):\n",
    "    \"\"\"\n",
    "    运行单个配置\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    a : str\n",
    "        处理方式: 'node' 或 'datemean'\n",
    "    b : str\n",
    "        IQR倍数选项: '1.0', '1.5', '2.0', '2.5', '3.0', '4.0'\n",
    "    c : str\n",
    "        QA选项: 'noqa', 'qaloose', 'qastrict'\n",
    "    d : str\n",
    "        版本选项: 'VersionD', 'VersionC'\n",
    "    e : str or None\n",
    "        平滑窗口大小: '3', '5', '7' (仅对datemean有效，node时为None)\n",
    "    common_data : dict\n",
    "        共享数据\n",
    "    \"\"\"\n",
    "    global _GLOBAL_SMOOTH_WINDOW\n",
    "    \n",
    "    # 构建配置标识字符串\n",
    "    if e is not None:\n",
    "        config_str = f\"A={a}, B={b}, C={c}, D={d}, E={e}\"\n",
    "        file_suffix = f\"{a}_{b}_{c}_{d}_sw{e}_swotslp\"\n",
    "    else:\n",
    "        config_str = f\"A={a}, B={b}, C={c}, D={d}\"\n",
    "        file_suffix = f\"{a}_{b}_{c}_{d}_swotslp\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running configuration: {config_str}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # 步骤1: 计算宽度统计（使用IQR方法）\n",
    "    print(\"Step 1: Calculating width statistics using IQR method...\")\n",
    "    df_l8 = common_data['df_l8']\n",
    "    df_w_stats = WidthStatistics.calculate_width_iqr(df_l8)\n",
    "    \n",
    "    # 使用IQR方法获取列名\n",
    "    low_col, high_col = WidthStatistics.get_iqr_columns(b)\n",
    "    df_w_stats['w_low'] = df_w_stats[low_col]\n",
    "    df_w_stats['w_high'] = df_w_stats[high_col]\n",
    "    \n",
    "    df_w_stats.to_csv(f'1.width_statistic_iqr_{file_suffix}.csv', index=False)\n",
    "    \n",
    "    df_comid = common_data['df_comid']\n",
    "    df_attrs = common_data['df_attrs']\n",
    "\n",
    "    # 根据c选项加载SWOT数据\n",
    "    if c == 'noqa':\n",
    "        # noqa时文件名固定\n",
    "        df_swot = pd.read_csv(f'1.all_matched_points_{d}.csv')\n",
    "    else:\n",
    "        # qaloose或qastrict时，文件名根据a确定\n",
    "        df_swot = pd.read_csv(f'2.swot_{a}_{c}_{d}.csv')\n",
    "   \n",
    "    df_swot = df_swot.merge(df_comid, on='stationid', how='inner')\n",
    "\n",
    "    if a == 'node':\n",
    "        print(\"Step 2: Selecting best nodes...\")\n",
    "        df_swot_filtered, df_nodes = NodeSelector.select_best_nodes(df_swot, min_data_points=10)\n",
    "        \n",
    "        print(\"Step 3: Applying quality control...\")\n",
    "        qc = DataQualityControl(df_w_stats)\n",
    "        df_qc = qc.apply_qc(df_swot_filtered, draw_figure=False)\n",
    "        \n",
    "    elif a == 'datemean':\n",
    "        print(f\"Using smoothed data with window={e} (skipping width filter)...\")\n",
    "        \n",
    "        # 设置全局滑动窗口大小\n",
    "        _GLOBAL_SMOOTH_WINDOW = int(e)\n",
    "        \n",
    "        # 使用进程池并行处理滑动中值\n",
    "        groups = [group for _, group in df_swot.groupby('stationid')]\n",
    "        \n",
    "        with mp.Pool(processes=N_WORKERS) as pool:\n",
    "            results = pool.map(_rolling_median_group, groups)\n",
    "        \n",
    "        df_qc = pd.concat(results)\n",
    "    \n",
    "    if 'COMID' not in df_qc.columns:\n",
    "        df_qc = df_qc.merge(df_comid, on='stationid', how='left')\n",
    "    \n",
    "    cols = ['COMID'] + [col for col in df_qc.columns if col != 'COMID']\n",
    "    df_qc = df_qc[cols]\n",
    "    df_qc.to_csv(f'2.swot-points-selection_iqr_{file_suffix}.csv', index=False)\n",
    "    \n",
    "    # 步骤4: 拟合\n",
    "    print(\"Step 4: Fitting hydraulic curves...\")\n",
    "    # 根据a选项决定是否跳过宽度筛选\n",
    "    skip_width_filter = (a == 'datemean')\n",
    "    fitter = HydraulicCurveFitter(df_w_stats, df_attrs, skip_width_filter=skip_width_filter)\n",
    "    df_fit_all = fitter.fit_all_stations(df_qc)\n",
    "    \n",
    "    if df_fit_all is None or len(df_fit_all) == 0:\n",
    "        print(f\"No fit data for {file_suffix}\")\n",
    "        return\n",
    "    \n",
    "    df_fit_all.to_csv(f'3.fit_proba_modified_q50_iqr_{file_suffix}.csv', index=False)\n",
    "    \n",
    "    # 步骤5: 生成曲线\n",
    "    print(\"Step 5: Generating hypsometric curves...\")\n",
    "    df_hypso = HypsometricCurveGenerator.generate_curves(df_fit_all)\n",
    "    \n",
    "    if df_hypso is None or len(df_hypso) == 0:\n",
    "        print(f\"No hypsometric curves generated for {file_suffix}\")\n",
    "        return\n",
    "    \n",
    "    df_hypso.to_csv(f'4.hypso_med_modified_q50_iqr_{file_suffix}.csv', index=False)\n",
    "    \n",
    "    # 步骤6: 验证\n",
    "    print(\"Step 6: Validating model...\")\n",
    "    validator = ModelValidator()\n",
    "    df_width = common_data['df_width']\n",
    "    \n",
    "    # 【修改】传入 skip_width_filter 参数\n",
    "    df_results = validator.validate(\n",
    "        df_hypso, df_width,\n",
    "        '/home/xj/device5/data/daily_Q',\n",
    "        df_fit_all,\n",
    "        skip_width_filter=skip_width_filter  # 传递参数\n",
    "    )\n",
    "    \n",
    "    if df_results is None or len(df_results) == 0:\n",
    "        print(f\"No validation results for {file_suffix}\")\n",
    "        return\n",
    "    \n",
    "    df_results.to_csv(f'5.q_kge_med_modified_q50_iqr_{file_suffix}.csv', index=False)\n",
    "    \n",
    "    print(f\"Configuration {file_suffix} completed!\")\n",
    "    gc.collect()\n",
    "\n",
    "# ============================================================================\n",
    "# 配置生成函数\n",
    "# ============================================================================\n",
    "def generate_configs():\n",
    "    \"\"\"\n",
    "    生成所有有效的配置组合\n",
    "    规则: \n",
    "    - noqa只和node组合\n",
    "    - qaloose和qastrict可以和所有A选项组合\n",
    "    - datemean模式增加E选项(smooth window): 3, 5, 7\n",
    "    - node模式E选项为None\n",
    "    \n",
    "    B选项现在是IQR倍数: '1.0', '1.5', '2.0', '2.5', '3.0', '4.0'\n",
    "    \"\"\"\n",
    "    A_options = ['node']\n",
    "    B_options = ['1.5']  # IQR倍数\n",
    "    C_options = ['noqa']\n",
    "    D_options = ['VersionD']\n",
    "    E_options = ['3', '5', '7']  # 新增：平滑窗口选项（仅datemean使用）\n",
    "    \n",
    "    configs = []\n",
    "    \n",
    "    for a in A_options:\n",
    "        for b in B_options:\n",
    "            for c in C_options:\n",
    "                for d in D_options:\n",
    "                    # noqa只和node组合\n",
    "                    if c == 'noqa' and a != 'node':\n",
    "                        continue\n",
    "                    \n",
    "                    if a == 'datemean':\n",
    "                        # datemean模式：遍历所有smooth window选项\n",
    "                        for e in E_options:\n",
    "                            configs.append((a, b, c, d, e))\n",
    "                    else:\n",
    "                        # node模式：E选项为None\n",
    "                        configs.append((a, b, c, d, None))\n",
    "    \n",
    "    return configs\n",
    "\n",
    "# ============================================================================\n",
    "# 主程序\n",
    "# ============================================================================\n",
    "def main():\n",
    "    \"\"\"主程序流程\"\"\"\n",
    "    import time\n",
    "    total_start = time.time()\n",
    "    \n",
    "    print(\"Loading common data...\")\n",
    "    df_l8 = pd.read_csv('../2-preprocess/1.gages3000_glow_datemean_width_timeseries.csv')\n",
    "    df_comid = pd.read_csv('../2-preprocess/4.q50_weighted_slp.csv')[['stationid', 'COMID']]\n",
    "    df_attrs = pd.read_csv('../2-preprocess/4.q50_weighted_slp.csv')[['stationid','COMID','q50','q50_weighted','slope']].drop_duplicates(subset = ['stationid'])\n",
    "    df_mid   = pd.read_csv('1.all_matched_points_VersionD.csv')[['reach_id','stationid']]\n",
    "    df_swotslope = pd.read_csv('3.swot_slope_VersionD.csv')\n",
    "    df_swotslope = df_swotslope.merge(df_mid,on='reach_id',how='left')#[['stationid','slope']]\n",
    "    df_swotslope = df_swotslope.drop_duplicates(subset = 'stationid')\n",
    "    slope_map = df_swotslope.set_index('stationid')['slope']\n",
    "    df_attrs['slope'] = df_attrs['stationid'].map(slope_map).fillna(df_attrs['slope'])\n",
    "    \n",
    "    df_width = pd.read_csv('../2-preprocess/1.gages3000_glow_datemean_width_timeseries.csv')\n",
    "    df_width['date'] = pd.to_datetime(df_width['date'])\n",
    "    \n",
    "    common_data = {\n",
    "        'df_l8': df_l8,\n",
    "        'df_comid': df_comid,\n",
    "        'df_attrs': df_attrs,\n",
    "        'df_width': df_width\n",
    "    }\n",
    "    \n",
    "    # 生成有效配置\n",
    "    configs = generate_configs()\n",
    "    \n",
    "    print(f\"\\nTotal configurations to run: {len(configs)}\")\n",
    "    print(\"Configurations:\")\n",
    "    for cfg in configs:\n",
    "        if cfg[4] is not None:\n",
    "            print(f\"  A={cfg[0]}, B={cfg[1]}, C={cfg[2]}, D={cfg[3]}, E={cfg[4]}\")\n",
    "        else:\n",
    "            print(f\"  A={cfg[0]}, B={cfg[1]}, C={cfg[2]}, D={cfg[3]}\")\n",
    "    \n",
    "    # 运行所有配置\n",
    "    for a, b, c, d, e in configs:\n",
    "        start = time.time()\n",
    "        run_configuration(a, b, c, d, e, common_data)\n",
    "        if e is not None:\n",
    "            print(f\"Time for ({a}, {b}, {c}, {d}, {e}): {time.time() - start:.2f}s\")\n",
    "        else:\n",
    "            print(f\"Time for ({a}, {b}, {c}, {d}): {time.time() - start:.2f}s\")\n",
    "    \n",
    "    # 生成箱型图\n",
    "    print(\"\\nGenerating boxplot comparisons...\")\n",
    "    metrics = ['kge', 'nse', 'nrmse']\n",
    "    data_dict = {metric: [] for metric in metrics}\n",
    "    labels = []\n",
    "    \n",
    "    for a, b, c, d, e in configs:\n",
    "        if e is not None:\n",
    "            file_suffix = f\"{a}_{b}_{c}_{d}_sw{e}\"\n",
    "        else:\n",
    "            file_suffix = f\"{a}_{b}_{c}_{d}\"\n",
    "        \n",
    "        file = f'5.q_kge_med_modified_q50_iqr_{file_suffix}.csv'\n",
    "        if os.path.exists(file):\n",
    "            df = pd.read_csv(file)\n",
    "            labels.append(file_suffix)\n",
    "            for metric in metrics:\n",
    "                station_metrics = df.groupby('stationid')[metric].mean().values\n",
    "                data_dict[metric].append(station_metrics)\n",
    "        \n",
    "    for metric in metrics:\n",
    "        if data_dict[metric]:\n",
    "            fig, ax = plt.subplots(figsize=(18, 6))\n",
    "            ax.boxplot(data_dict[metric], labels=labels)\n",
    "            ax.set_title(f'{metric.upper()} Boxplot Comparison')\n",
    "            ax.set_xlabel('Configuration (A_B_C_D[_swE])')\n",
    "            ax.set_ylabel(metric.upper())\n",
    "            plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'boxplot_{metric}.png', dpi=150)\n",
    "            plt.close()\n",
    "    \n",
    "    print(f\"\\nTotal time: {time.time() - total_start:.2f}s\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
