{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff98006e-3d4b-4d32-9cd3-f9420ae54e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station Brazil_10800000 length < 10. Skipping...\n",
      "station Brazil_15325000 length < 10. Skipping...\n",
      "station Brazil_16080000 length < 10. Skipping...\n",
      "station Brazil_18870000 length < 10. Skipping...\n",
      "station Brazil_19150000 length < 10. Skipping...\n",
      "station Brazil_56846080 length < 10. Skipping...\n",
      "station Brazil_60235005 length < 10. Skipping...\n",
      "station Brazil_64517000 length < 10. Skipping...\n",
      "station Brazil_83461000 length < 10. Skipping...\n",
      "station Canada_03QC003 length < 10. Skipping...\n",
      "station Chile_08319001 length < 10. Skipping...\n",
      "station EWA_9110302 length < 10. Skipping...\n",
      "station GRDC_1112100 length < 10. Skipping...\n",
      "station GRDC_1112300 length < 10. Skipping...\n",
      "station GRDC_1134040 length < 10. Skipping...\n",
      "station GRDC_1134200 length < 10. Skipping...\n",
      "station GRDC_1134400 length < 10. Skipping...\n",
      "station GRDC_1134450 length < 10. Skipping...\n",
      "station GRDC_1134460 length < 10. Skipping...\n",
      "station GRDC_1134480 length < 10. Skipping...\n",
      "station GRDC_1134630 length < 10. Skipping...\n",
      "station GRDC_1496500 length < 10. Skipping...\n",
      "station GRDC_1531600 length < 10. Skipping...\n",
      "station GRDC_1737100 length < 10. Skipping...\n",
      "station GRDC_1737150 length < 10. Skipping...\n",
      "station GRDC_1748500 length < 10. Skipping...\n",
      "station GRDC_1749500 length < 10. Skipping...\n",
      "station GRDC_1813200 length < 10. Skipping...\n",
      "station GRDC_1813450 length < 10. Skipping...\n",
      "station GRDC_1835900 length < 10. Skipping...\n",
      "station GRDC_2369905 length < 10. Skipping...\n",
      "station GRDC_2469112 length < 10. Skipping...\n",
      "station GRDC_2469140 length < 10. Skipping...\n",
      "station GRDC_2548400 length < 10. Skipping...\n",
      "station GRDC_2587220 length < 10. Skipping...\n",
      "station GRDC_2906880 length < 10. Skipping...\n",
      "station GRDC_2910606 length < 10. Skipping...\n",
      "station GRDC_2911300 length < 10. Skipping...\n",
      "station GRDC_3106300 length < 10. Skipping...\n",
      "station GRDC_3206800 length < 10. Skipping...\n",
      "station GRDC_3469150 length < 10. Skipping...\n",
      "station GRDC_3512400 length < 10. Skipping...\n",
      "station GRDC_3844400 length < 10. Skipping...\n",
      "station GRDC_4102700 length < 10. Skipping...\n",
      "station GRDC_4102740 length < 10. Skipping...\n",
      "station GRDC_4103750 length < 10. Skipping...\n",
      "station GRDC_4203503 length < 10. Skipping...\n",
      "station GRDC_4208120 length < 10. Skipping...\n",
      "station GRDC_4214940 length < 10. Skipping...\n",
      "station GRDC_4356600 length < 10. Skipping...\n",
      "station GRDC_4356700 length < 10. Skipping...\n",
      "station GRDC_4873280 length < 10. Skipping...\n",
      "station GRDC_4876800 length < 10. Skipping...\n",
      "station GRDC_5223600 length < 10. Skipping...\n",
      "station GRDC_6348400 length < 10. Skipping...\n",
      "station GRDC_6348500 length < 10. Skipping...\n",
      "station GRDC_6348800 length < 10. Skipping...\n",
      "station GRDC_6688900 length < 10. Skipping...\n",
      "station GRDC_6691650 length < 10. Skipping...\n",
      "station GRDC_6981800 length < 10. Skipping...\n",
      "station GRDC_6990700 length < 10. Skipping...\n",
      "station USGS_03146500 length < 10. Skipping...\n",
      "station USGS_06259000 length < 10. Skipping...\n",
      "station USGS_07076517 length < 10. Skipping...\n",
      "station USGS_09512406 length < 10. Skipping...\n",
      "station USGS_15291000 length < 10. Skipping...\n",
      "station USGS_15291200 length < 10. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DRAW_FIGURE = False\n",
    "\n",
    "# NSE (Nash-Sutcliffe Efficiency)\n",
    "def nse(observed, simulated):\n",
    "    return 1 - (np.sum((observed - simulated) ** 2) / np.sum((observed - np.mean(observed)) ** 2))\n",
    "\n",
    "# KGE (Kling-Gupta Efficiency)\n",
    "def kge(observed, simulated):\n",
    "    r = np.corrcoef(observed, simulated)[0, 1]\n",
    "    alpha = np.mean(simulated) / np.mean(observed)\n",
    "    beta  = np.std(simulated)/np.mean(simulated) / (np.std(observed)/np.mean(observed))\n",
    "    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "\n",
    "# Relative RMSE\n",
    "def relative_rmse(observed, simulated):\n",
    "    rmse = np.sqrt(mean_squared_error(observed, simulated))\n",
    "    return rmse / np.mean(observed)\n",
    "\n",
    "def fit_function(w,  z0, u1, s1):\n",
    "    return z0 + u1 * (w ** s1)\n",
    "\n",
    "folder_path = 'daily_long'\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "width_df = pd.read_csv('../2-preprocess/1.gages3000_glow_datemean_width_timeseries.csv')\n",
    "width_df['date'] = pd.to_datetime(width_df['date'], errors='coerce')  # Similarly for width_df\n",
    "\n",
    "w50_df = pd.read_csv('../3-process/1.width_range.csv').drop_duplicates(subset=['stationid'])\n",
    "q50_df = pd.read_csv('../2-preprocess/4.q50_weighted_slp.csv').drop_duplicates(subset=['stationid'])\n",
    "\n",
    "stationids = sorted(w50_df['stationid'].unique())\n",
    "\n",
    "# 创建一个空的DataFrame用于存储所有数据\n",
    "pds = pd.DataFrame()\n",
    "\n",
    "# 从1979-01-01开始，逐日增加\n",
    "start_date = pd.to_datetime('1979-01-01')\n",
    "\n",
    "df_res = []\n",
    "co, co_ori = 0, 0\n",
    "\n",
    "for s in stationids:\n",
    "    file_path = os.path.join(folder_path, s+'.csv')\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    \n",
    "    df_val = pd.read_csv(file_path)\n",
    "    # 生成逐日增加的时间列\n",
    "    num_days = len(df_val)\n",
    "    time_range = pd.date_range(start=start_date, periods=num_days, freq='D')\n",
    "    df_val['date'] = time_range\n",
    "    df_val['stationid'] = s\n",
    "    df_val = df_val.dropna(subset=['qobs'])\n",
    "    df_val = df_val.merge(width_df[width_df['stationid']==s],on=['stationid','date'],how = 'inner')\n",
    "    w50 = w50_df[w50_df['stationid'] == s]['w50'].values[0]\n",
    "    q50 = q50_df[q50_df['stationid'] == s]['q50'].values[0]\n",
    "    coefficient = q50/(w50**(8.0/3.0))\n",
    "    df_val['Q_est'] = df_val['width'] ** (8.0 / 3.0) *coefficient\n",
    "    df_val = df_val.dropna()\n",
    "    if len(df_val)<10:\n",
    "        print(f\"station {s} length < 10. Skipping...\")\n",
    "        continue\n",
    "        \n",
    "\n",
    "    df_val['kge'] = kge(df_val['qobs'], df_val['Q_est'])\n",
    "    df_val['nse'] = nse(df_val['qobs'], df_val['Q_est'])\n",
    "    df_val['nrmse'] = relative_rmse(df_val['qobs'], df_val['Q_est'])\n",
    "    df_res.append(df_val[['stationid','date','width','qobs','Q_est','kge','nse','nrmse']])\n",
    "\n",
    "\n",
    "#print(co, co_ori, co/co_ori)\n",
    "df_res = pd.concat(df_res, ignore_index=True)\n",
    "df_res.to_csv('W83_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cdc6cd-7379-4c63-b0b9-a901adf215d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def KGE(y_true, y_pred):  # improved 2012\n",
    "    correlation = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "    alpha = (np.std(y_pred)/np.mean(y_pred)) / (np.std(y_true)/np.mean(y_true))\n",
    "    beta = np.mean(y_pred) / np.mean(y_true)\n",
    "    return 1 - np.sqrt((correlation - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "\n",
    "\n",
    "# 定义计算NSE的函数\n",
    "def NSE(observed, simulated):\n",
    "    return 1 - np.sum((observed - simulated) ** 2) / np.sum((observed - np.mean(observed)) ** 2)\n",
    "\n",
    "# 定义计算rRMSE的函数\n",
    "def nRMSE(observed, simulated):\n",
    "    rmse = np.sqrt(mean_squared_error(observed, simulated))\n",
    "    return rmse / np.mean(observed)\n",
    "\n",
    "# 定义计算CC的函数\n",
    "def CC(observed, simulated):\n",
    "    return pearsonr(observed, simulated)[0]  # 使用Spearman相关系数作为CC\n",
    "\n",
    "valid = []\n",
    "for s in stationids:\n",
    "    df_station = df_res[df_res['stationid']==s]\n",
    "    if len(df_station)<10:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    observed = df_station['qobs']\n",
    "    simulated = df_station['Q_est']\n",
    "    cc = CC(observed, simulated)\n",
    "    nrmse = nRMSE(observed, simulated)\n",
    "    kge = KGE(observed, simulated)\n",
    "    nse = NSE(observed, simulated)\n",
    "    pbias = (simulated.mean() / observed.mean() - 1) \n",
    "    rv    = simulated.std() / simulated.mean()/ (observed.std() / observed.mean())\n",
    "    valid.append({'stationid': s, 'KGE': kge, 'NSE': nse,'NRMSE': nrmse,'CC': cc, 'pBIAS': pbias, 'RV': rv})\n",
    "\n",
    "\n",
    "valid_df = pd.DataFrame(valid)\n",
    "valid_df.to_csv('validation_W83.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc2c55e-8f40-4b06-8cc9-1d35f9354981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce9853-2616-4224-abdc-e91916faf771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
